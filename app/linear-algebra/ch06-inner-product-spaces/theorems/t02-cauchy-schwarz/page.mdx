export const metadata = {
  title: 'Cauchy-Schwarz Inequality — Linear Algebra — Math Notes',
}

import { Breadcrumbs } from '@/components/layout/Breadcrumbs'
import { Tag } from '@/components/ui/Tag'
import { StatusBadge } from '@/components/ui/StatusBadge'

<Breadcrumbs items={[
  { label: "선형대수", href: "/linear-algebra" },
  { label: "6. 내적공간", href: "/linear-algebra/ch06-inner-product-spaces" },
  { label: "Theorem — Cauchy-Schwarz Inequality" },
]} />

<div className="mb-6">
  <div className="flex items-center gap-3 mb-3">
    <Tag type="theorem" />
    <StatusBadge status="complete" />
  </div>
</div>

# Cauchy-Schwarz Inequality

The Cauchy--Schwarz inequality is arguably the single most important inequality in mathematics. It bounds the inner product of two vectors by the product of their norms, provides the foundation for defining angles, and implies the triangle inequality. It holds in every inner product space, from $\mathbb{R}^n$ to $L^2$ function spaces.

---

## Statement

<Theorem title="Cauchy-Schwarz Inequality" number="6.5">
For all vectors $u, v$ in an inner product space $V$:

$$|\langle u, v \rangle| \leq \|u\| \cdot \|v\|.$$

Equality holds if and only if $u$ and $v$ are linearly dependent (i.e., one is a scalar multiple of the other).
</Theorem>

---

## Special cases

<Example id="cs-dot-product" title="Cauchy-Schwarz for the dot product">
In $\mathbb{R}^n$: $|x \cdot y| \leq \|x\| \cdot \|y\|$, or equivalently:

$$\left(\sum_{i=1}^n x_i y_i\right)^2 \leq \left(\sum_{i=1}^n x_i^2\right) \left(\sum_{i=1}^n y_i^2\right).$$

For $x = (1, 2, 3)$, $y = (4, 5, 6)$: $|x \cdot y| = |4 + 10 + 18| = 32$ and $\|x\| \cdot \|y\| = \sqrt{14} \cdot \sqrt{77} = \sqrt{1078} \approx 32.83$. So $32 \leq 32.83$ ✓.
</Example>

<Example id="cs-integral" title="Cauchy-Schwarz for integrals">
For continuous functions on $[a, b]$:

$$\left|\int_a^b f(x)g(x)\,dx\right|^2 \leq \int_a^b f(x)^2\,dx \cdot \int_a^b g(x)^2\,dx.$$

For $f(x) = x$ and $g(x) = 1$ on $[0, 1]$: $|\int_0^1 x\,dx|^2 = \frac{1}{4}$ and $\int_0^1 x^2\,dx \cdot \int_0^1 1\,dx = \frac{1}{3}$. So $\frac{1}{4} \leq \frac{1}{3}$ ✓.
</Example>

<Example id="cs-sum" title="Cauchy-Schwarz for finite sums (classical form)">
For real numbers $a_1, \ldots, a_n$ and $b_1, \ldots, b_n$:

$$(a_1 b_1 + \cdots + a_n b_n)^2 \leq (a_1^2 + \cdots + a_n^2)(b_1^2 + \cdots + b_n^2).$$

For $n = 2$: $(a_1 b_1 + a_2 b_2)^2 \leq (a_1^2 + a_2^2)(b_1^2 + b_2^2)$. Expanding: $a_1^2 b_1^2 + 2a_1 b_1 a_2 b_2 + a_2^2 b_2^2 \leq a_1^2 b_1^2 + a_1^2 b_2^2 + a_2^2 b_1^2 + a_2^2 b_2^2$. The difference is $(a_1 b_2 - a_2 b_1)^2 \geq 0$ ✓.
</Example>

---

## Equality condition

<Example id="cs-equality" title="When equality holds">
Equality in $|\langle u, v \rangle| = \|u\| \|v\|$ iff $u = \alpha v$ or $v = 0$.

$u = (2, 4)$, $v = (1, 2)$: $|\langle u, v \rangle| = |2 + 8| = 10$ and $\|u\| \|v\| = \sqrt{20} \cdot \sqrt{5} = 10$. Equality holds since $u = 2v$.

$u = (1, 0)$, $v = (0, 1)$: $|\langle u, v \rangle| = 0$ and $\|u\| \|v\| = 1$. Strict inequality because $u$ and $v$ are linearly independent.
</Example>

<Example id="cs-angle" title="Angle interpretation">
The Cauchy--Schwarz inequality is equivalent to $|\cos\theta| \leq 1$ where $\theta$ is the angle between $u$ and $v$:

$$\cos\theta = \frac{\langle u, v \rangle}{\|u\| \|v\|} \in [-1, 1].$$

Equality ($|\cos\theta| = 1$) means $\theta = 0$ or $\theta = \pi$, i.e., the vectors are parallel.
</Example>

---

## Consequences

<Theorem title="Triangle inequality (from Cauchy-Schwarz)">
For all $u, v$: $\|u + v\| \leq \|u\| + \|v\|$.
</Theorem>

<Proof title="Derivation from Cauchy-Schwarz">
$\|u + v\|^2 = \langle u + v, u + v \rangle = \|u\|^2 + 2\operatorname{Re}\langle u, v \rangle + \|v\|^2 \leq \|u\|^2 + 2|\langle u, v \rangle| + \|v\|^2 \leq \|u\|^2 + 2\|u\|\|v\| + \|v\|^2 = (\|u\| + \|v\|)^2$.
</Proof>

<Example id="triangle" title="Triangle inequality in R^2">
$u = (3, 0)$, $v = (0, 4)$: $\|u + v\| = 5 \leq 3 + 4 = 7$.

$u = (1, 2)$, $v = (3, 6)$: $\|u + v\| = \|(4, 8)\| = 4\sqrt{5}$ and $\|u\| + \|v\| = \sqrt{5} + 3\sqrt{5} = 4\sqrt{5}$. Equality because $v = 3u$.
</Example>

<Example id="reverse-triangle" title="Reverse triangle inequality">
Also from Cauchy--Schwarz: $|\|u\| - \|v\|| \leq \|u - v\|$.

$u = (5, 0)$, $v = (3, 4)$: $|\|u\| - \|v\|| = |5 - 5| = 0 \leq \|(2, -4)\| = 2\sqrt{5}$ ✓.
</Example>

---

## Applications

<Example id="cs-probability" title="Correlation coefficient">
In probability, the Cauchy--Schwarz inequality applied to $\langle X, Y \rangle = E[XY]$ (with mean-centered random variables) gives:

$$|E[XY]|^2 \leq E[X^2] \cdot E[Y^2],$$

or equivalently $|\operatorname{Cov}(X, Y)| \leq \sigma_X \sigma_Y$. The **correlation coefficient** $\rho = \frac{\operatorname{Cov}(X,Y)}{\sigma_X \sigma_Y}$ satisfies $|\rho| \leq 1$ by Cauchy--Schwarz.
</Example>

<Example id="cs-am-qm" title="AM-QM inequality from Cauchy-Schwarz">
Apply Cauchy--Schwarz to $a = (a_1, \ldots, a_n)$ and $b = (1, 1, \ldots, 1)$:

$$(a_1 + \cdots + a_n)^2 \leq n(a_1^2 + \cdots + a_n^2),$$

i.e., $\left(\frac{a_1 + \cdots + a_n}{n}\right)^2 \leq \frac{a_1^2 + \cdots + a_n^2}{n}$, which says AM $\leq$ QM (arithmetic mean at most quadratic mean).

For $a = (1, 2, 3)$: $\text{AM} = 2$, $\text{QM} = \sqrt{14/3} \approx 2.16$. So $2 \leq 2.16$ ✓.
</Example>

<Example id="cs-series" title="Cauchy-Schwarz for infinite series">
For sequences $(a_n)$ and $(b_n)$ with $\sum a_n^2 < \infty$ and $\sum b_n^2 < \infty$:

$$\left(\sum_{n=1}^\infty a_n b_n\right)^2 \leq \sum_{n=1}^\infty a_n^2 \cdot \sum_{n=1}^\infty b_n^2.$$

For $a_n = 1/n$ and $b_n = 1/n^2$: $\sum a_n b_n = \sum 1/n^3 = \zeta(3) \approx 1.202$, $\sum a_n^2 = \pi^2/6$, $\sum b_n^2 = \pi^4/90$. So $\zeta(3)^2 \approx 1.44 \leq \frac{\pi^2}{6} \cdot \frac{\pi^4}{90} \approx 1.78$ ✓.
</Example>

<Example id="cs-optimization" title="Maximizing a linear functional">
The maximum of $\langle u, v \rangle$ subject to $\|u\| = 1$ is $\|v\|$, achieved when $u = v / \|v\|$.

This follows directly from Cauchy--Schwarz: $\langle u, v \rangle \leq |\langle u, v \rangle| \leq \|u\| \|v\| = \|v\|$.

Example: maximize $x + 2y + 3z$ subject to $x^2 + y^2 + z^2 = 1$. This is $\langle (x,y,z), (1,2,3) \rangle$ with $\|(x,y,z)\| = 1$. Maximum is $\|(1,2,3)\| = \sqrt{14}$, achieved at $(x,y,z) = \frac{1}{\sqrt{14}}(1,2,3)$.
</Example>

<Example id="cs-determinant" title="Hadamard's inequality from Cauchy-Schwarz">
For a matrix $A$ with columns $a_1, \ldots, a_n$, repeated application of Cauchy--Schwarz (via Gram--Schmidt) gives Hadamard's inequality:

$$|\det A| \leq \|a_1\| \cdot \|a_2\| \cdots \|a_n\|.$$

Equality holds iff the columns are orthogonal. This is because Gram--Schmidt gives $A = QR$ with $|\det A| = |\det R| = r_{11} \cdots r_{nn}$ and $r_{jj} = \|u_j\| \leq \|v_j\| = \|a_j\|$.
</Example>

---

## Summary

<Remark title="The most fundamental inequality">
The Cauchy--Schwarz inequality underpins the entire structure of inner product spaces:
- It ensures the **angle** between vectors is well-defined.
- It implies the **triangle inequality**, making every inner product space a metric space.
- It bounds **correlations** in probability ($|\rho| \leq 1$).
- It gives **Hadamard's bound** on determinants.
- It provides the **optimality condition** for maximizing linear functionals.
- Its equality case characterizes **linear dependence** of two vectors.
</Remark>
