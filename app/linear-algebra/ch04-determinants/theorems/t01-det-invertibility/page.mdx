export const metadata = {
  title: 'Determinant and Invertibility — Linear Algebra — Math Notes',
}

import { Breadcrumbs } from '@/components/layout/Breadcrumbs'
import { Tag } from '@/components/ui/Tag'
import { StatusBadge } from '@/components/ui/StatusBadge'

<Breadcrumbs items={[
  { label: "선형대수", href: "/linear-algebra" },
  { label: "4. 행렬식", href: "/linear-algebra/ch04-determinants" },
  { label: "Theorem — Determinant and Invertibility" },
]} />

<div className="mb-6">
  <div className="flex items-center gap-3 mb-3">
    <Tag type="theorem" />
    <StatusBadge status="complete" />
  </div>
</div>

# Determinant and Invertibility

The determinant provides a clean, scalar-valued criterion for invertibility: a matrix is invertible if and only if its determinant is nonzero.

---

## Statement

<Theorem title="Determinant characterizes invertibility" number="4.3">
Let $A \in M_{n \times n}(F)$. Then

$$A \text{ is invertible} \iff \det(A) \neq 0.$$

Equivalently, $A$ is singular if and only if $\det(A) = 0$.
</Theorem>

<Proof>
**($\Rightarrow$)** If $A$ is invertible, then $AA^{-1} = I$, so $\det(A)\det(A^{-1}) = \det(I) = 1$. Hence $\det(A) \neq 0$.

**($\Leftarrow$)** If $\det(A) \neq 0$, then $B = \frac{1}{\det(A)}\text{adj}(A)$ satisfies $AB = I$ (by the adjugate formula). So $A$ is invertible with $A^{-1} = B$.

Alternatively: row-reduce $A$ to an upper triangular matrix $U$. The row operations multiply the determinant by nonzero scalars and $\pm 1$. So $\det(A) \neq 0$ iff $\det(U) \neq 0$ iff all diagonal entries of $U$ are nonzero iff $U$ has $n$ pivots iff $A$ is row-equivalent to $I_n$ iff $A$ is invertible.
</Proof>

---

## Examples

<Example id="2x2-test" title="2 x 2 invertibility test">
$A = \begin{pmatrix} 3 & 5 \\ 1 & 2 \end{pmatrix}$: $\det = 6 - 5 = 1 \neq 0$. Invertible. $A^{-1} = \begin{pmatrix} 2 & -5 \\ -1 & 3 \end{pmatrix}$.

$B = \begin{pmatrix} 2 & 6 \\ 1 & 3 \end{pmatrix}$: $\det = 6 - 6 = 0$. Singular.
</Example>

<Example id="3x3-test" title="3 x 3 invertibility test">
$A = \begin{pmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 9 \end{pmatrix}$: $\det = 0$ (the third row is the sum of the other two rows minus the first, or compute directly: $1(45-48) - 2(36-42) + 3(32-35) = -3 + 12 - 9 = 0$). Singular.

$B = \begin{pmatrix} 1 & 2 & 3 \\ 4 & 5 & 6 \\ 7 & 8 & 10 \end{pmatrix}$: $\det = 1(50-48) - 2(40-42) + 3(32-35) = 2 + 4 - 9 = -3 \neq 0$. Invertible.
</Example>

<Example id="product-det" title="Determinant of a product">
$\det(AB) = \det(A)\det(B)$. So:
- $AB$ is invertible iff both $A$ and $B$ are invertible.
- $\det(A^n) = (\det A)^n$.
- $\det(A^{-1}) = 1/\det(A)$.
</Example>

<Example id="det-transpose" title="A and A^T have same determinant">
$\det(A^T) = \det(A)$, so $A$ is invertible iff $A^T$ is invertible. This means: the rows of $A$ are linearly independent iff the columns are linearly independent (which also follows from row rank = column rank).
</Example>

<Example id="block-det" title="Block diagonal determinant">
$$\det\begin{pmatrix} A & 0 \\ 0 & B \end{pmatrix} = \det(A) \cdot \det(B).$$

So this block diagonal matrix is invertible iff both $A$ and $B$ are invertible.
</Example>

<Example id="parametric-det" title="Parametric invertibility">
For which values of $t$ is $A = \begin{pmatrix} 1 & t \\ t & 1 \end{pmatrix}$ invertible?

$\det(A) = 1 - t^2 = (1-t)(1+t)$. So $A$ is invertible for all $t \neq \pm 1$.
</Example>

<Example id="det-linear-dep" title="Columns dependent iff det = 0">
$\det(A) = 0$ means the columns of $A$ are linearly dependent. Geometrically, the column vectors lie in a lower-dimensional subspace, so the parallelepiped they span has zero volume.
</Example>

<Example id="det-eigenvalue" title="Connection to eigenvalues">
$\det(A) = \prod_{i=1}^n \lambda_i$ where $\lambda_i$ are the eigenvalues (counted with algebraic multiplicity). So $\det(A) = 0$ iff some eigenvalue is $0$ iff $A$ has a nontrivial kernel.
</Example>

<Example id="det-field" title="Determinant over finite fields">
Over $\mathbb{F}_2 = \{0, 1\}$: $\det\begin{pmatrix} 1 & 1 \\ 1 & 0 \end{pmatrix} = 0 - 1 = -1 = 1 \neq 0$ (in $\mathbb{F}_2$). The matrix is invertible over $\mathbb{F}_2$. Its inverse is $\begin{pmatrix} 0 & 1 \\ 1 & 1 \end{pmatrix}$.
</Example>

<Example id="det-orthogonal" title="Orthogonal matrices">
If $A$ is orthogonal ($A^T A = I$), then $\det(A)^2 = \det(A^T)\det(A) = \det(I) = 1$, so $\det(A) = \pm 1$. The **special orthogonal group** $\text{SO}(n)$ consists of orthogonal matrices with $\det = +1$ (rotations).
</Example>

<Example id="det-singular-set" title="Singular matrices form a hypersurface">
The set $\{A \in M_{n \times n}(\mathbb{R}) \mid \det(A) = 0\}$ is a single polynomial equation in $n^2$ variables. It is a hypersurface of dimension $n^2 - 1$ in $M_{n \times n}(\mathbb{R}) \cong \mathbb{R}^{n^2}$. The invertible matrices form the complement -- a dense open set.
</Example>

<Example id="det-change-of-basis" title="Similar matrices have equal determinants">
If $B = P^{-1}AP$, then $\det(B) = \det(P)^{-1}\det(A)\det(P) = \det(A)$. The determinant is a **similarity invariant**, hence an invariant of the underlying linear operator $T$ (independent of the choice of basis).
</Example>

---

## The determinant as a group homomorphism

<Remark title="Algebraic structure">
The determinant map $\det : \text{GL}_n(F) \to F^*$ is a **group homomorphism** from the general linear group to the multiplicative group of $F$:

$$\det(AB) = \det(A) \cdot \det(B).$$

Its kernel is the **special linear group**: $\text{SL}_n(F) = \{A \in \text{GL}_n(F) \mid \det(A) = 1\}$.
</Remark>

<Remark title="Looking ahead">
The determinant appears throughout linear algebra:
- [Cramer's Rule](/linear-algebra/ch04-determinants/theorems/t02-cramers-rule) for solving systems
- The **characteristic polynomial** $\det(A - \lambda I)$ for eigenvalues
- The **Jacobian determinant** in multivariable calculus (change of variables)
- **Exterior algebra** and differential forms
</Remark>
