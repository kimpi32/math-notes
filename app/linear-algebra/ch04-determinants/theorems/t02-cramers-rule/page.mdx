export const metadata = {
  title: "Cramer's Rule — Linear Algebra — Math Notes",
}

import { Breadcrumbs } from '@/components/layout/Breadcrumbs'
import { Tag } from '@/components/ui/Tag'
import { StatusBadge } from '@/components/ui/StatusBadge'

<Breadcrumbs items={[
  { label: "선형대수", href: "/linear-algebra" },
  { label: "4. 행렬식", href: "/linear-algebra/ch04-determinants" },
  { label: "Theorem — Cramer's Rule" },
]} />

<div className="mb-6">
  <div className="flex items-center gap-3 mb-3">
    <Tag type="theorem" />
    <StatusBadge status="complete" />
  </div>
</div>

# Cramer's Rule

**Cramer's Rule** gives an explicit formula for the solution of a system of linear equations in terms of determinants. While computationally expensive for large systems, it is theoretically elegant and useful for symbolic and small-scale computations.

---

## Statement

<Theorem title="Cramer's Rule" number="4.4">
Let $A \in M_{n \times n}(F)$ be invertible and $b \in F^n$. The unique solution $x = (x_1, \ldots, x_n)$ of the system $Ax = b$ is given by

$$x_i = \frac{\det(A_i(b))}{\det(A)}$$

for $i = 1, 2, \ldots, n$, where $A_i(b)$ is the matrix obtained from $A$ by replacing the $i$-th column with $b$.
</Theorem>

<Proof>
Since $A$ is invertible, $x = A^{-1}b$. By the adjugate formula, $A^{-1} = \frac{1}{\det(A)}\text{adj}(A)$, so

$$x_i = (A^{-1}b)_i = \frac{1}{\det(A)} \sum_{j=1}^n (\text{adj}(A))_{ij} b_j = \frac{1}{\det(A)} \sum_{j=1}^n C_{ji} b_j.$$

Now $\sum_{j=1}^n b_j C_{ji}$ is the cofactor expansion of $\det(A_i(b))$ along column $i$ (since the $i$-th column of $A_i(b)$ is $b$, and the cofactors for column $i$ are computed from the other columns, which are the same as in $A$).
</Proof>

---

## Examples

<Example id="2x2-cramer" title="2 x 2 system">
Solve $\begin{pmatrix} 2 & 1 \\ 5 & 3 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 4 \\ 11 \end{pmatrix}$.

$\det(A) = 6 - 5 = 1$.

$$x = \frac{\det\begin{pmatrix} 4 & 1 \\ 11 & 3 \end{pmatrix}}{\det(A)} = \frac{12 - 11}{1} = 1, \quad y = \frac{\det\begin{pmatrix} 2 & 4 \\ 5 & 11 \end{pmatrix}}{\det(A)} = \frac{22 - 20}{1} = 2.$$

Solution: $(x, y) = (1, 2)$. Verify: $2(1) + 1(2) = 4$ and $5(1) + 3(2) = 11$.
</Example>

<Example id="3x3-cramer" title="3 x 3 system">
Solve: $x + 2z = 6$, $-3x + 4y + 6z = 30$, $-x - 2y + 3z = 8$.

$$A = \begin{pmatrix} 1 & 0 & 2 \\ -3 & 4 & 6 \\ -1 & -2 & 3 \end{pmatrix}, \quad b = \begin{pmatrix} 6 \\ 30 \\ 8 \end{pmatrix}.$$

$\det(A) = 1(12+12) - 0 + 2(6+4) = 24 + 20 = 44$.

$$x = \frac{\det\begin{pmatrix} 6 & 0 & 2 \\ 30 & 4 & 6 \\ 8 & -2 & 3 \end{pmatrix}}{44} = \frac{6(12+12) - 0 + 2(-60-32)}{44} = \frac{144 - 184}{44} = \frac{-40}{44} = -\frac{10}{11}.$$

Similarly one computes $y$ and $z$.
</Example>

<Example id="symbolic-cramer" title="Symbolic/parametric system">
Solve $ax + by = e$, $cx + dy = f$ with $ad - bc \neq 0$:

$$x = \frac{ed - bf}{ad - bc}, \quad y = \frac{af - ce}{ad - bc}.$$

Cramer's Rule gives a closed-form solution that makes dependence on parameters transparent.
</Example>

<Example id="determinant-zero" title="When Cramer's Rule fails">
If $\det(A) = 0$, Cramer's Rule does not apply. The system $Ax = b$ either has no solution or infinitely many solutions, depending on whether $b \in C(A)$.

$\begin{pmatrix} 1 & 2 \\ 2 & 4 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 3 \\ 6 \end{pmatrix}$: $\det = 0$. Infinitely many solutions: $x = 3 - 2t$, $y = t$.

$\begin{pmatrix} 1 & 2 \\ 2 & 4 \end{pmatrix}\begin{pmatrix} x \\ y \end{pmatrix} = \begin{pmatrix} 3 \\ 7 \end{pmatrix}$: $\det = 0$ and $b \notin C(A)$. No solution.
</Example>

<Example id="single-variable" title="Solving for one variable">
A key advantage of Cramer's Rule: to find just $x_3$ in a $5 \times 5$ system, compute only two determinants ($\det(A)$ and $\det(A_3(b))$), rather than solving the full system. This can be more efficient than row reduction if only one variable is needed.
</Example>

<Example id="theoretical-use" title="Theoretical applications">
Cramer's Rule is rarely used for numerical computation (too expensive for large $n$), but it is invaluable in theory:

- It shows the solution of $Ax = b$ depends **rationally** on the entries of $A$ and $b$.
- It proves that solutions vary smoothly (or algebraically) with parameters.
- It is used in algebraic geometry to study families of linear systems.
</Example>

<Example id="inverse-cramer" title="Inverse via Cramer's Rule">
Setting $b = e_j$ in $Ax = e_j$ gives the $j$-th column of $A^{-1}$:

$$(A^{-1})_{ij} = \frac{\det(A_i(e_j))}{\det(A)} = \frac{C_{ji}}{\det(A)} = \frac{(\text{adj}(A))_{ij}}{\det(A)}.$$

This recovers the adjugate formula $A^{-1} = \frac{1}{\det(A)}\text{adj}(A)$.
</Example>

<Example id="complex-system" title="Complex system">
Solve $(1+i)z_1 + 2z_2 = 3$ and $iz_1 + (1-i)z_2 = 1$ over $\mathbb{C}$:

$\det(A) = (1+i)(1-i) - 2i = 2 - 2i$.

$z_1 = \frac{3(1-i) - 2}{2 - 2i} = \frac{1 - 3i}{2 - 2i}$. Rationalize by multiplying by $\overline{2-2i} = 2 + 2i$:

$z_1 = \frac{(1-3i)(2+2i)}{(2-2i)(2+2i)} = \frac{2 + 2i - 6i - 6i^2}{8} = \frac{8 - 4i}{8} = 1 - \frac{i}{2}$.
</Example>

<Example id="cramers-geometry" title="Geometric interpretation in R^2">
For $Ax = b$ in $\mathbb{R}^2$: $x_1 = \frac{\det(b, a_2)}{\det(a_1, a_2)}$ where $a_1, a_2$ are the columns of $A$.

$\det(b, a_2)$ is the signed area of the parallelogram spanned by $b$ and $a_2$, and $\det(a_1, a_2)$ is the signed area spanned by $a_1$ and $a_2$. The ratio gives the "proportion" of $a_1$ needed to reach $b$ from the $a_2$ direction.
</Example>

<Example id="cramers-multilinear" title="Multilinear algebra viewpoint">
Cramer's Rule is a consequence of the multilinear and alternating nature of the determinant. Replacing column $i$ by $b = \sum x_j a_j$ and using multilinearity:

$$\det(a_1, \ldots, b, \ldots, a_n) = \sum_{j} x_j \det(a_1, \ldots, a_j, \ldots, a_n) = x_i \det(A)$$

since $\det$ vanishes when two columns are equal. This is the deepest way to understand Cramer's Rule.
</Example>

<Example id="numerical-cost" title="Computational cost">
Cramer's Rule requires computing $n + 1$ determinants of $n \times n$ matrices. Using cofactor expansion, this is $O(n \cdot n!) = O((n+1)!)$. Even using LU decomposition for each determinant, it is $O(n \cdot n^3) = O(n^4)$, compared to $O(n^3)$ for Gaussian elimination on the augmented matrix.
</Example>

<Example id="formal-cramer" title="Cramer's Rule over general rings">
Over a commutative ring $R$ (not necessarily a field), Cramer's Rule still holds in the form: $\det(A) \cdot x_i = \det(A_i(b))$. If $\det(A)$ is a unit in $R$, we can divide. If not, the formula still gives useful information (e.g., $\det(A)$ annihilates the cokernel of the map defined by $A$).
</Example>

---

<Remark title="Summary">
Cramer's Rule converts the problem of solving a linear system into the problem of computing determinants. While impractical for large numerical systems, it provides:

1. An explicit, closed-form formula for solutions
2. A proof that solutions depend rationally on the coefficients
3. Geometric insight via the volume interpretation of determinants
4. A theoretical tool in algebra and algebraic geometry
</Remark>
